{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "Phân cụm là một bài toán học không được giám sát, thường được sử dụng khi bạn không có nhãn dữ liệu. \n",
    "\n",
    "Phân cụm K-Means là một trong những thuật toán phân cụm phổ biến. Mục tiêu của thuật toán này là tìm các nhóm (các cụm) trong các dữ liệu nhất định. \n",
    "\n",
    "Xây dựng phân cụm KMeans được thực hiện theo ý tưởng sau:\n",
    "- Chọn ra k tâm ngẫu nhiên của các cụm.\n",
    "- Gán mỗi dữ liệu $x_i$ vào cụm có tâm gần nó nhất, bằng cách tính khoảng cách từ $x_i$ đến các tâm\n",
    "- Chọn lại tâm cụm bằng cách tính lại tâm nhờ các điểm thuộc cụm\n",
    "- Lặp lại các bước trên cho đến khi không có sự thay đổi về các điểm trong cụm.\n",
    "\n",
    "Trong bài này chúng ta sẽ thực hiện cài đặt thuật toán phân cụm K-means từ đầu.\n",
    "\n",
    "![title](https://i.imgur.com/k4XcapI.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import một số thư viện cần thiết.\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sử dụng một mẹo nhỏ để vẽ hình trên cùng một dòng thay vì mở cửa sổ mới\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # đặt kích thước mặc định cho hình\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Một mẹo nhỏ để notebook tự load lại các module bên ngoài;\n",
    "# xem thêm tại http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (120, 4)\n",
      "Training labels shape:  (120,)\n",
      "Test data shape:  (30, 4)\n",
      "Test labels shape:  (30,)\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu hoa cẩm chướng từ Scikit-learn.\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, \\\n",
    "                                                    iris.target, test_size=0.2)\n",
    "\n",
    "# In ra kích thước dữ liệu huấn luyện và dữ liệu kiểm tra như một \n",
    "# phép thử đơn giản.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, chúng ta cần cài đặt hàm huấn luyện mô hình K-means. Trong phần này, K-means thực hiện việc học cách phân cụm dữ liệu từ dữ liệu huấn luyện.\n",
    "\n",
    "Như đã nêu ở trên, việc học cách phân cụm được thực hiện theo 4 bước:\n",
    "- Chọn ra k tâm ngẫu nhiên của các cụm.\n",
    "- Gán mỗi dữ liệu $x_i$ vào cụm có tâm gần nó nhất, bằng cách tính khoảng cách từ $x_i$ đến các tâm\n",
    "- Chọn lại tâm cụm bằng cách tính lại tâm nhờ các điểm thuộc cụm\n",
    "- Lặp lại các bước trên cho đến khi không có sự thay đổi về các điểm trong cụm.\n",
    "\n",
    "** Bài tập: ** Mở tệp `k_means.py` và cài đặt hàm `train()`. Trong phần này, để tiện tính toán, ta cài đặt đồng thời các hàm `compute_distances`.\n",
    "\n",
    "*Gợi ý: Tham khảo K-Nearest Neighbor để cài đặt các hàm compute_distances.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_means import KMeans\n",
    "\n",
    "# Khởi tạo bộ phân cụm KMeans. \n",
    "# Chọn số lượng các cụm cần phân ra, trong trường hợp này, ta chọn số cụm\n",
    "# bằng số lượng các loại hoa cẩm chướng\n",
    "cluster = KMeans(num_clusters=3)\n",
    "\n",
    "# Mở tệp k_means.py và cài đặt hàm huấn luyện train().\n",
    "cluster.train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 / 30 correct => accuracy: 0.000000\n",
      "Got 8 / 30 correct => accuracy: 0.266667\n",
      "Got 8 / 30 correct => accuracy: 0.266667\n",
      "Got 25 / 30 correct => accuracy: 0.833333\n",
      "Got 5 / 30 correct => accuracy: 0.166667\n",
      "Got 14 / 30 correct => accuracy: 0.466667\n",
      "(1, 2, 0)\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Bây giờ, cài đặt hàm predict_labels và chạy code dưới đây:\n",
    "# Chúng ta dùng k = 3 (Số lượng cụm ứng với các nhãn cần phân biệt).\n",
    "from itertools import  permutations\n",
    "\n",
    "num_test = X_test.shape[0]\n",
    "dists = cluster.compute_distances_no_loops(X_test)\n",
    "y_test_pred = cluster.predict_clusters(dists)\n",
    "\n",
    "labels = [0,1,2]\n",
    "best_acc = 0\n",
    "y_new = np.zeros_like(y_test)\n",
    "\n",
    "for perm in permutations(labels):\n",
    "    y_new[y_test == perm[0]] = 0\n",
    "    y_new[y_test == perm[1]] = 1\n",
    "    y_new[y_test == perm[2]] = 2\n",
    "\n",
    "# Tính ra in ra tỉ lệ những ví dụ dự đoán đúng\n",
    "    num_correct = np.sum(y_test_pred == y_new)\n",
    "    accuracy = float(num_correct) / num_test\n",
    "    if accuracy > best_acc : \n",
    "        best_acc = accuracy\n",
    "        true_label = perm\n",
    "        \n",
    "    print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "    \n",
    "print(true_label)\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Bài tập: ** Điều chỉnh code để sau khi phân cụm, nhãn phân cụm trả về là nhãn tương ứng với loại hoa cẩm chướng của cụm đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
